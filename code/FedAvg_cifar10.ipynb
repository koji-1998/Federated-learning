{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "vkZxat4Y-IsQ",
    "outputId": "da86392c-66e8-4b60-b471-086e745cdcbc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from torch import nn, optim\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change seed\n",
    "trial_times = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed):\n",
    "    ## random\n",
    "    random.seed(seed)\n",
    "    ## Numpy\n",
    "    np.random.seed(seed)\n",
    "    ## Pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 42 + trial_times -1\n",
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "O0TfzOhU-QlG"
   },
   "outputs": [],
   "source": [
    "class Argments():\n",
    "  def __init__(self):\n",
    "    self.batch_size = 64\n",
    "    self.test_batch = 1000\n",
    "    self.global_epochs = 100\n",
    "    self.local_epochs = 5\n",
    "    self.lr = 0.01\n",
    "    self.momentum = 0.9\n",
    "    self.weight_decay = 10**-4.0\n",
    "    self.partience = 1000\n",
    "    self.worker_num = 10\n",
    "    self.sample_num = 10\n",
    "    self.unlabeleddata_size = None\n",
    "    self.device = torch.device('cuda:0'if torch.cuda.is_available() else'cpu')\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    self.alpha_label = 1.0\n",
    "    self.alpha_size = 10\n",
    "\n",
    "args = Argments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'FedAvg_cifar10_{}times'.format(str(trial_times))\n",
    "result_path = '../result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FedAvg_cifar10_1times\n"
     ]
    }
   ],
   "source": [
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "r5PuCcqmJNUQ"
   },
   "outputs": [],
   "source": [
    "class LocalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out_data = self.data[idx]\n",
    "        out_label = self.label[idx]\n",
    "        if self.transform:\n",
    "            out_data = self.transform(out_data)\n",
    "        return out_data, out_label\n",
    "    \n",
    "class DatasetFromSubset(torch.utils.data.Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.subset[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "    \n",
    "class GlobalDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,federated_dataset,transform=None):\n",
    "    self.transform = transform\n",
    "    self.data = []\n",
    "    self.label = []\n",
    "    for dataset in federated_dataset:\n",
    "      for (data,label) in dataset:\n",
    "        self.data.append(data)\n",
    "        self.label.append(label)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    out_data = self.data[idx]\n",
    "    out_label = self.label[idx]\n",
    "    if self.transform:\n",
    "        out_data = self.transform(out_data)\n",
    "    return out_data, out_label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "class UnlabeledDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self,transform=None):\n",
    "    self.transform = transform\n",
    "    self.data = []\n",
    "    self.target = None\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    out_data = self.data[idx]\n",
    "    out_label = 'unlabeled'\n",
    "    if self.transform:\n",
    "        out_data = self.transform(out_data)\n",
    "    return out_data, out_label\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(Centralized=False,unlabeled_data=False):\n",
    "    \n",
    "    transform_train = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.RandomCrop(32, padding=2),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.491372549, 0.482352941, 0.446666667), (0.247058824, 0.243529412, 0.261568627))])\n",
    "    transform_test = transforms.Compose([transforms.ToPILImage(),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize((0.491372549, 0.482352941, 0.446666667), (0.247058824, 0.243529412, 0.261568627))])\n",
    "\n",
    "    # トレーニングデータをダウンロード\n",
    "    all_trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True)\n",
    "    #trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "    # テストデータをダウンロード\n",
    "    all_testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True)\n",
    "    #testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "    \n",
    "    ## get unlabeled dataset\n",
    "    if unlabeled_data:\n",
    "        unlabeled_dataset = UnlabeledDataset(transform_test)\n",
    "        idx = sorted(random.sample(range(len(all_trainset)),args.unlabeleddata_size))\n",
    "        unlabeled_dataset.data = np.array([all_trainset.data[i]  for i in idx])\n",
    "        all_trainset.data = np.delete(all_trainset.data,idx,0)\n",
    "        all_trainset.targets = np.delete(all_trainset.targets,idx,0)\n",
    "    all_train_data = np.array(all_trainset.data)\n",
    "    all_train_label = np.array(all_trainset.targets)\n",
    "    all_test_data = np.array(all_testset.data)\n",
    "    all_test_label = np.array(all_testset.targets)\n",
    "    print('Train:{} Test:{}'.format(len(all_train_data),len(all_test_data)))\n",
    "\n",
    "\n",
    "    ## Data size heterogeneity\n",
    "    data_proportions = np.random.dirichlet(np.repeat(args.alpha_size, args.worker_num))\n",
    "    train_data_proportions = np.array([0 for _ in range(args.worker_num)])\n",
    "    test_data_proportions = np.array([0 for _ in range(args.worker_num)])\n",
    "    for i in range(len(data_proportions)):\n",
    "        if i==(len(data_proportions)-1):\n",
    "            train_data_proportions = train_data_proportions.astype('int64')\n",
    "            test_data_proportions = test_data_proportions.astype('int64')\n",
    "            train_data_proportions[-1] = len(all_train_data) - np.sum(train_data_proportions[:-1])\n",
    "            test_data_proportions[-1] = len(all_test_data) - np.sum(test_data_proportions[:-1])\n",
    "        else:\n",
    "            train_data_proportions[i] = (data_proportions[i] * len(all_train_data))\n",
    "            test_data_proportions[i] = (data_proportions[i] * len(all_test_data))\n",
    "    min_size = 0\n",
    "    K = 10\n",
    "\n",
    "    '''\n",
    "    label_list = np.arange(10)\n",
    "    np.random.shuffle(label_list)\n",
    "    '''\n",
    "    label_list = list(range(K))\n",
    "\n",
    "\n",
    "    ## Data distribution heterogeneity\n",
    "    while min_size<10:\n",
    "        idx_train_batch = [[] for _ in range(args.worker_num)]\n",
    "        idx_test_batch = [[] for _ in range(args.worker_num)]\n",
    "        for k in label_list:\n",
    "            proportions_train = np.random.dirichlet(np.repeat(args.alpha_label, args.worker_num))\n",
    "            proportions_test = copy.deepcopy(proportions_train)\n",
    "            idx_k_train = np.where(all_train_label == k)[0]\n",
    "            idx_k_test = np.where(all_test_label == k)[0]\n",
    "            np.random.shuffle(idx_k_train)\n",
    "            np.random.shuffle(idx_k_test)\n",
    "            ## Balance (train)\n",
    "            proportions_train = np.array([p*(len(idx_j)<train_data_proportions[i]) for i,(p,idx_j) in enumerate(zip(proportions_train,idx_train_batch))])\n",
    "            proportions_train = proportions_train/proportions_train.sum()\n",
    "            proportions_train = (np.cumsum(proportions_train)*len(idx_k_train)).astype(int)[:-1]\n",
    "            idx_train_batch = [idx_j + idx.tolist() for idx_j,idx in zip(idx_train_batch,np.split(idx_k_train,proportions_train))]\n",
    "\n",
    "            ## Balance (test)\n",
    "            proportions_test = np.array([p*(len(idx_j)<test_data_proportions[i]) for i,(p,idx_j) in enumerate(zip(proportions_test,idx_test_batch))])\n",
    "            proportions_test = proportions_test/proportions_test.sum()\n",
    "            proportions_test = (np.cumsum(proportions_test)*len(idx_k_test)).astype(int)[:-1]\n",
    "            idx_test_batch = [idx_j + idx.tolist() for idx_j,idx in zip(idx_test_batch,np.split(idx_k_test,proportions_test))]\n",
    "\n",
    "            min_size = min([len(idx_j) for idx_j in idx_train_batch])\n",
    "\n",
    "    federated_trainset = []\n",
    "    federated_testset = []\n",
    "    for i in range(args.worker_num):\n",
    "        ## create trainset\n",
    "        data = [all_train_data[idx] for idx in idx_train_batch[i]]\n",
    "        label = [all_train_label[idx] for idx in idx_train_batch[i]]\n",
    "        federated_trainset.append(LocalDataset())\n",
    "        federated_trainset[-1].data = data\n",
    "        federated_trainset[-1].label = label\n",
    "\n",
    "        ## create testset\n",
    "        data = [all_test_data[idx] for idx in idx_test_batch[i]]\n",
    "        label = [all_test_label[idx] for idx in idx_test_batch[i]]\n",
    "        federated_testset.append(LocalDataset())\n",
    "        federated_testset[-1].data = data\n",
    "        federated_testset[-1].label = label\n",
    "\n",
    "        \n",
    "    ## split trainset\n",
    "    federated_valset = [None]*args.worker_num\n",
    "    for i in range(args.worker_num):\n",
    "        n_samples = len(federated_trainset[i])\n",
    "        if n_samples==1:\n",
    "            train_subset = federated_trainset[i]\n",
    "            val_subset = copy.deepcopy(federated_trainset[i])\n",
    "        else:\n",
    "            train_size = int(len(federated_trainset[i]) * 0.8) \n",
    "            val_size = n_samples - train_size \n",
    "            train_subset,val_subset = torch.utils.data.random_split(federated_trainset[i], [train_size, val_size])\n",
    "\n",
    "        federated_trainset[i] = DatasetFromSubset(train_subset)\n",
    "        federated_valset[i] = DatasetFromSubset(val_subset)\n",
    "\n",
    "    ## show data distribution\n",
    "    H = 2\n",
    "    W = 5\n",
    "    fig, axs = plt.subplots(H, W, figsize=(20, 5))\n",
    "    x = np.arange(1,11)\n",
    "    for i, (trainset,valset,testset) in enumerate(zip(federated_trainset,federated_valset,federated_testset)):\n",
    "        bottom = [0]*10\n",
    "        count = [0]*10\n",
    "        for _,label in trainset:\n",
    "            count[label] += 1\n",
    "        axs[int(i/W), i%W].bar(x, count,bottom=bottom)\n",
    "        for j in range(len(count)):\n",
    "            bottom[j]+=count[j]\n",
    "        count = [0]*10\n",
    "        for _,label in valset:\n",
    "            count[label] += 1\n",
    "        axs[int(i/W), i%W].bar(x, count,bottom=bottom)\n",
    "        for j in range(len(count)):\n",
    "            bottom[j]+=count[j]\n",
    "        count = [0]*10\n",
    "        for _,label in testset:\n",
    "            count[label] += 1\n",
    "        axs[int(i/W), i%W].bar(x, count,bottom=bottom)\n",
    "        #axs[int(i/W), i%W].title(\"worker{}\".format(i+1), fontsize=12, color = \"green\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    ## get global dataset\n",
    "    if Centralized:\n",
    "        global_trainset = GlobalDataset(federated_trainset)\n",
    "        global_valset = GlobalDataset(federated_valset)\n",
    "        global_testset =  GlobalDataset(federated_testset)\n",
    "        \n",
    "        ## show_cifer(global_trainset.data,global_testset.label, cifar10_labels)\n",
    "\n",
    "        global_trainset.transform = transform_train\n",
    "        global_valset.transform = transform_test\n",
    "        global_testset.transform = transform_test\n",
    "\n",
    "        global_trainloader = torch.utils.data.DataLoader(global_trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "        global_valloader = torch.utils.data.DataLoader(global_valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "        global_testloader = torch.utils.data.DataLoader(global_testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "\n",
    "    ## set transform\n",
    "    for i in range(args.worker_num):\n",
    "        federated_trainset[i].transform = transform_train\n",
    "        federated_valset[i].transform = transform_test\n",
    "        federated_testset[i].transform = transform_test\n",
    "    \n",
    "    if Centralized and unlabeled_data:\n",
    "        return federated_trainset,federated_valset,federated_testset,global_trainloader,global_valloader,global_testloader,unlabeled_dataset\n",
    "    if Centralized:\n",
    "        return federated_trainset,federated_valset,federated_testset,global_trainloader,global_valloader,global_testloader\n",
    "    elif unlabeled_data:\n",
    "        return federated_trainset,federated_valset,federated_testset,unlabeled_dataset\n",
    "    else:\n",
    "        return federated_trainset,federated_valset,federated_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train:50000 Test:10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "federated_trainset,federated_valset,federated_testset = get_dataset(unlabeled_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39994, 10006, 10000]\n"
     ]
    }
   ],
   "source": [
    "## 確認\n",
    "total = [0,0,0]\n",
    "for i in range(args.worker_num):\n",
    "    total[0]+=len(federated_trainset[i])\n",
    "    total[1]+=len(federated_valset[i])\n",
    "    total[2]+=len(federated_testset[i])\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZU3vAAb9-6SD"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    '''\n",
    "    VGG model \n",
    "    '''\n",
    "    def __init__(self, features, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "        ## Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            ## print(\"in_channels: {}, v: {}\".format(in_channels, v))\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "          512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGGConvBlocks(nn.Module):\n",
    "    '''\n",
    "    VGG containers that only contains the conv layers \n",
    "    '''\n",
    "    def __init__(self, features, num_classes=10):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        ## Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class VGGContainer(nn.Module):\n",
    "    '''\n",
    "    VGG model \n",
    "    '''\n",
    "    def __init__(self, features, input_dim, hidden_dims, num_classes=10):\n",
    "        super(VGGContainer, self).__init__()\n",
    "        self.features = features\n",
    "        ## note: we hard coded here a bit by assuming we only have two hidden layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(hidden_dims[1], num_classes),\n",
    "        )\n",
    "        ## Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def matched_vgg11(matched_shapes):\n",
    "    # [(67, 27), (67,), (132, 603), (132,), (260, 1188), (260,), (261, 2340), (261,), (516, 2349), (516,), (517, 4644), (517,), \n",
    "    # (516, 4653), (516,), (516, 4644), (516,), (516, 515), (515,), (515, 515), (515,), (515, 10), (10,)]\n",
    "    processed_matched_shape = [matched_shapes[0][0], \n",
    "                                'M', \n",
    "                                matched_shapes[2][0], \n",
    "                                'M', \n",
    "                                matched_shapes[4][0], \n",
    "                                matched_shapes[6][0], \n",
    "                                'M', \n",
    "                                matched_shapes[8][0], \n",
    "                                matched_shapes[10][0], \n",
    "                                'M', \n",
    "                                matched_shapes[12][0], \n",
    "                                matched_shapes[14][0], \n",
    "                                'M']\n",
    "    return VGGContainer(make_layers(processed_matched_shape), input_dim=matched_shapes[16][0], \n",
    "            hidden_dims=[matched_shapes[16][1], matched_shapes[18][1]], num_classes=10)\n",
    "\n",
    "\n",
    "def vgg11():\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\")\"\"\"\n",
    "    return VGG(make_layers(cfg['A']))\n",
    "\n",
    "\n",
    "def vgg11_bn(num_classes=10):\n",
    "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['A'], batch_norm=True), num_classes=num_classes)\n",
    "\n",
    "\n",
    "def vgg13():\n",
    "    \"\"\"VGG 13-layer model (configuration \"B\")\"\"\"\n",
    "    return VGG(make_layers(cfg['B']))\n",
    "\n",
    "\n",
    "def vgg13_bn():\n",
    "    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['B'], batch_norm=True))\n",
    "\n",
    "\n",
    "def vgg16():\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\")\"\"\"\n",
    "    return VGG(make_layers(cfg['D']))\n",
    "\n",
    "\n",
    "def vgg16_bn():\n",
    "    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['D'], batch_norm=True))\n",
    "\n",
    "\n",
    "def vgg19():\n",
    "    \"\"\"VGG 19-layer model (configuration \"E\")\"\"\"\n",
    "    return VGG(make_layers(cfg['E']))\n",
    "\n",
    "\n",
    "def vgg19_bn():\n",
    "    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\"\"\"\n",
    "    return VGG(make_layers(cfg['E'], batch_norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Yu90X1TWJVKJ"
   },
   "outputs": [],
   "source": [
    "class Server():\n",
    "  def __init__(self):\n",
    "    self.model = vgg13()\n",
    "\n",
    "  def create_worker(self,federated_trainset,federated_valset,federated_testset):\n",
    "    workers = []\n",
    "    for i in range(args.worker_num):\n",
    "      workers.append(Worker(federated_trainset[i],federated_valset[i],federated_testset[i]))\n",
    "    return workers\n",
    "\n",
    "  def sample_worker(self,workers):\n",
    "    sample_worker = []\n",
    "    sample_worker_num = random.sample(range(args.worker_num),args.sample_num)\n",
    "    for i in sample_worker_num:\n",
    "      sample_worker.append(workers[i])\n",
    "    return sample_worker\n",
    "\n",
    "\n",
    "  def send_model(self,workers):\n",
    "    nums = 0\n",
    "    for worker in workers:\n",
    "      nums += worker.train_data_num\n",
    "\n",
    "    for worker in workers:\n",
    "      worker.aggregation_weight = 1.0*worker.train_data_num/nums\n",
    "      worker.model = copy.deepcopy(self.model)\n",
    "      worker.model = worker.model.to(args.device)\n",
    "\n",
    "  def aggregate_model(self,workers):   \n",
    "    new_params = OrderedDict()\n",
    "    for i,worker in enumerate(workers):\n",
    "      worker_state = worker.model.state_dict()\n",
    "      for key in worker_state.keys():\n",
    "        if i==0:\n",
    "          new_params[key] = worker_state[key]*worker.aggregation_weight\n",
    "        else:\n",
    "          new_params[key] += worker_state[key]*worker.aggregation_weight\n",
    "      worker.model = worker.model.to('cpu')\n",
    "      del worker.model\n",
    "    self.model.load_state_dict(new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LDWEBjgfJYFc"
   },
   "outputs": [],
   "source": [
    "class Worker():\n",
    "  def __init__(self,trainset,valset,testset):\n",
    "    self.trainloader = torch.utils.data.DataLoader(trainset,batch_size=args.batch_size,shuffle=True,num_workers=2)\n",
    "    self.valloader = torch.utils.data.DataLoader(valset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.testloader = torch.utils.data.DataLoader(testset,batch_size=args.test_batch,shuffle=False,num_workers=2)\n",
    "    self.model = None\n",
    "    self.train_data_num = len(trainset)\n",
    "    self.test_data_num = len(testset)\n",
    "    self.aggregation_weight = None\n",
    "\n",
    "  def local_train(self):\n",
    "    acc_train,loss_train = train(self.model,args.criterion,self.trainloader,args.local_epochs)\n",
    "    acc_valid,loss_valid = test(self.model,args.criterion,self.valloader)\n",
    "    return acc_train,loss_train,acc_valid,loss_valid\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7-GY66gROuEU"
   },
   "outputs": [],
   "source": [
    "def train(model,criterion,trainloader,epochs):\n",
    "  optimizer = optim.SGD(model.parameters(),lr=args.lr,momentum=args.momentum,weight_decay=args.weight_decay)\n",
    "  model.train()\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    for (data,labels) in trainloader:\n",
    "      data,labels = Variable(data),Variable(labels)\n",
    "      data,labels = data.to(args.device),labels.to(args.device)\n",
    "      optimizer.zero_grad()\n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs,labels)\n",
    "      running_loss += loss.item()\n",
    "      predicted = torch.argmax(outputs,dim=1)\n",
    "      correct += (predicted==labels).sum().item()\n",
    "      count += len(labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "  return 100.0*correct/count,running_loss/len(trainloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "oA4URv9mQ3xV"
   },
   "outputs": [],
   "source": [
    "def test(model,criterion,testloader):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  count = 0\n",
    "  for (data,labels) in testloader:\n",
    "    data,labels = data.to(args.device),labels.to(args.device)\n",
    "    outputs = model(data)\n",
    "    running_loss += criterion(outputs,labels).item()\n",
    "    predicted = torch.argmax(outputs,dim=1)\n",
    "    correct += (predicted==labels).sum().item()\n",
    "    count += len(labels)\n",
    "\n",
    "  accuracy = 100.0*correct/count\n",
    "  loss = running_loss/len(testloader)\n",
    "\n",
    "\n",
    "  return accuracy,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WMO7_WSLHeGl"
   },
   "outputs": [],
   "source": [
    "class Early_Stopping():\n",
    "  def __init__(self,partience):\n",
    "    self.step = 0\n",
    "    self.loss = float('inf')\n",
    "    self.partience = partience\n",
    "\n",
    "  def validate(self,loss):\n",
    "    if self.loss<loss:\n",
    "      self.step += 1\n",
    "      if self.step>self.partience:\n",
    "        return True\n",
    "    else:\n",
    "      self.step = 0\n",
    "      self.loss = loss\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "-noG_98IR-nZ",
    "outputId": "78a6ebe2-854a-4f83-dc45-5c4ac35b69e8"
   },
   "outputs": [],
   "source": [
    "server = Server()\n",
    "workers = server.create_worker(federated_trainset,federated_valset,federated_testset)\n",
    "acc_train = []\n",
    "loss_train = []\n",
    "acc_valid = []\n",
    "loss_valid = []\n",
    "\n",
    "early_stopping = Early_Stopping(args.partience)\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for epoch in range(args.global_epochs):\n",
    "  sample_worker = server.sample_worker(workers)\n",
    "  server.send_model(sample_worker)\n",
    "\n",
    "  acc_train_avg = 0.0\n",
    "  loss_train_avg = 0.0\n",
    "  acc_valid_avg = 0.0\n",
    "  loss_valid_avg = 0.0\n",
    "  for worker in sample_worker:\n",
    "    acc_train_tmp,loss_train_tmp,acc_valid_tmp,loss_valid_tmp = worker.local_train()\n",
    "    acc_train_avg += acc_train_tmp/len(sample_worker)\n",
    "    loss_train_avg += loss_train_tmp/len(sample_worker)\n",
    "    acc_valid_avg += acc_valid_tmp/len(sample_worker)\n",
    "    loss_valid_avg += loss_valid_tmp/len(sample_worker)\n",
    "  server.aggregate_model(sample_worker)\n",
    "  '''\n",
    "  server.model.to(args.device)\n",
    "  for worker in workers:\n",
    "    acc_valid_tmp,loss_valid_tmp = test(server.model,args.criterion,worker.valloader)\n",
    "    acc_valid_avg += acc_valid_tmp/len(workers)\n",
    "    loss_valid_avg += loss_valid_tmp/len(workers)\n",
    "  server.model.to('cpu')\n",
    "  '''\n",
    "  print('Epoch{}  loss:{}  accuracy:{}'.format(epoch+1,loss_valid_avg,acc_valid_avg))\n",
    "  acc_train.append(acc_train_avg)\n",
    "  loss_train.append(loss_train_avg)\n",
    "  acc_valid.append(acc_valid_avg)\n",
    "  loss_valid.append(loss_valid_avg)\n",
    "\n",
    "  if early_stopping.validate(loss_valid_avg):\n",
    "    print('Early Stop')\n",
    "    break\n",
    "    \n",
    "end = time.time()#終了時刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('学習時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "mi_uceyoptLP",
    "outputId": "bc067e09-01bc-4e65-daf9-ac2f42373cbd"
   },
   "outputs": [],
   "source": [
    "acc_test = []\n",
    "loss_test = []\n",
    "\n",
    "server.model.to(args.device)\n",
    "\n",
    "nums = 0\n",
    "for worker in workers:\n",
    "  nums += worker.test_data_num\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "  worker.aggregation_weight = 1.0*worker.test_data_num/nums\n",
    "  acc_tmp,loss_tmp = test(server.model,args.criterion,worker.testloader)\n",
    "  acc_test.append(acc_tmp)\n",
    "  loss_test.append(loss_tmp)\n",
    "  print('Worker{} accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_test_avg = sum(acc_test)/len(acc_test)\n",
    "loss_test_avg = sum(loss_test)/len(loss_test)\n",
    "print('Test  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('推論時間：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_tune_test = []\n",
    "loss_tune_test = []\n",
    "acc_tune_valid = []\n",
    "loss_tune_valid = []\n",
    "\n",
    "start = time.time()#開始時刻\n",
    "\n",
    "for i,worker in enumerate(workers):\n",
    "    worker.model = copy.deepcopy(server.model)\n",
    "    worker.model = worker.model.to(args.device)\n",
    "    _,_,acc_tmp,loss_tmp = worker.local_train()\n",
    "    acc_tune_valid.append(acc_tmp)\n",
    "    loss_tune_valid.append(loss_tmp)\n",
    "    print('Worker{} Valid accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    \n",
    "    acc_tmp,loss_tmp = test(worker.model,args.criterion,worker.testloader)\n",
    "    acc_tune_test.append(acc_tmp)\n",
    "    loss_tune_test.append(loss_tmp)\n",
    "    print('Worker{} Test accuracy:{}  loss:{}'.format(i+1,acc_tmp,loss_tmp))\n",
    "    worker.model = worker.model.to('cpu')\n",
    "    del worker.model\n",
    "\n",
    "end = time.time()#終了時刻\n",
    "\n",
    "acc_valid_avg = sum(acc_tune_valid)/len(acc_tune_valid)\n",
    "loss_valid_avg = sum(loss_tune_valid)/len(loss_tune_valid)\n",
    "print('Validation(tune)  loss:{}  accuracy:{}'.format(loss_valid_avg,acc_valid_avg))\n",
    "acc_test_avg = sum(acc_tune_test)/len(acc_tune_test)\n",
    "loss_test_avg = sum(loss_tune_test)/len(loss_tune_test)\n",
    "print('Test(tune)  loss:{}  accuracy:{}'.format(loss_test_avg,acc_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('学習・推論時間（fine-tune）：{}秒'.format(end-start))#終了時刻-開始時刻でかかった時間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save model\n",
    "\n",
    "if not os.path.exists('./'+filename):\n",
    "    print(\"make dir\")\n",
    "    os.makedirs('./'+filename)\n",
    "\n",
    "with open('./'+filename+'/global_model.pickle', 'wb') as f:\n",
    "    pickle.dump(server.model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train = pd.DataFrame(acc_train)\n",
    "loss_train = pd.DataFrame(loss_train)\n",
    "acc_valid = pd.DataFrame(acc_valid)\n",
    "loss_valid = pd.DataFrame(loss_valid)\n",
    "\n",
    "acc_test = pd.DataFrame(acc_test)\n",
    "loss_test = pd.DataFrame(loss_test)\n",
    "\n",
    "acc_tune_valid = pd.DataFrame(acc_tune_valid)\n",
    "loss_tune_valid = pd.DataFrame(loss_tune_valid)\n",
    "\n",
    "acc_tune_test = pd.DataFrame(acc_tune_test)\n",
    "loss_tune_test = pd.DataFrame(loss_tune_test)\n",
    "\n",
    "\n",
    "acc_train.to_csv(result_path+filename+'_train_acc.csv',index=False, header=False)\n",
    "loss_train.to_csv(result_path+filename+'_train_loss.csv',index=False, header=False)\n",
    "acc_valid.to_csv(result_path+filename+'_valid_acc.csv',index=False, header=False)\n",
    "loss_valid.to_csv(result_path+filename+'_valid_loss.csv',index=False, header=False)\n",
    "acc_test.to_csv(result_path+filename+'_test_acc.csv',index=False, header=False)\n",
    "loss_test.to_csv(result_path+filename+'_test_loss.csv',index=False, header=False)\n",
    "acc_tune_valid.to_csv(result_path+filename+'_fine-tune_valid_acc.csv',index=False, header=False)\n",
    "loss_tune_valid.to_csv(result_path+filename+'_fine-tune_valid_loss.csv',index=False, header=False)\n",
    "acc_tune_test.to_csv(result_path+filename+'_fine-tune_test_acc.csv',index=False, header=False)\n",
    "loss_tune_test.to_csv(result_path+filename+'_fine-tune_test_loss.csv',index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FedAvg_femnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
